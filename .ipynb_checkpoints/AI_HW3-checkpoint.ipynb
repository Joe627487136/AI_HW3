{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 1 and accuracy is 1/2 = 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import os, sys\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from getimagenetclasses import get_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(self, path, use_crop=True, crop_size=224, batch_size=50, max_iter=250):\n",
    "        self.path = path\n",
    "        self.totensor = transforms.ToTensor()\n",
    "        self.images = [i for i in os.listdir(path+'/imagespart/') if i[0] != '.']\n",
    "        self.crop_size = crop_size\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.use_crop = use_crop\n",
    "        \n",
    "    def load_image(self, filename):\n",
    "        img_name = os.path.splitext(filename)[0]\n",
    "        img = Image.open(self.path+'/imagespart/'+filename)\n",
    "        width, height = img.size\n",
    "        ratio = width/height\n",
    "        if width >= height:\n",
    "            tup = (int(ratio*280), 280)\n",
    "        else:\n",
    "            tup = (280, int(280/ratio))\n",
    "        img = img.resize(tup, PIL.Image.BICUBIC)\n",
    "        label = get_label(img_name)\n",
    "        img_tensor = self.totensor(img)\n",
    "        if img_tensor.size(0) == 1:\n",
    "            img_tensor = img_tensor.expand(3, -1, -1)\n",
    "        if self.use_crop:\n",
    "            return self.five_crops(img_tensor), torch.full((5,), label, dtype=torch.long)\n",
    "        else:\n",
    "            return self.crop(img_tensor, 0), torch.full((1,), label, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.load_image(self.images[index])\n",
    "    \n",
    "    def crop(self, img_tensor, loc=0):\n",
    "        # loc: 0 = center, 1 = top left, 2 = top right, 3 = btm left, 4 = btm right\n",
    "        H, W = img_tensor.size(1), img_tensor.size(2)\n",
    "        crop_size = self.crop_size\n",
    "        if loc==0:\n",
    "            Hs, Ws = int(H/2-crop_size/2), int(W/2-crop_size/2)\n",
    "            return img_tensor[:,Hs:Hs+crop_size,Ws:Ws+crop_size]\n",
    "        elif loc==1:\n",
    "            return img_tensor[:, :crop_size, :crop_size]\n",
    "        elif loc==2:\n",
    "            return img_tensor[:, :crop_size, -crop_size:]\n",
    "        elif loc==3:\n",
    "            return img_tensor[:, -crop_size:, :crop_size]\n",
    "        elif loc==4:\n",
    "            return img_tensor[:, -crop_size:, -crop_size:]\n",
    "        return \n",
    "    \n",
    "    def five_crops(self, img_tensor):\n",
    "        tensors = []\n",
    "        for i in range(5):\n",
    "            cropped = self.crop(img_tensor, i).unsqueeze(dim=0)\n",
    "            tensors.append(cropped)\n",
    "        return torch.cat(tensors, dim=0)\n",
    "    \n",
    "\n",
    "def test(model, device, test_loader, nsample, use_crop=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    match = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if use_crop:\n",
    "                c, w, h = data.size(2), data.size(3), data.size(4)\n",
    "                data = data.view(-1, c, w, h)\n",
    "            target = target.view(-1)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            match += pred.eq(target.view_as(pred)).sum().item()\n",
    "    if use_crop:\n",
    "        nsample *= 5\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print (\"Loss is {} and accuracy is {}/{} = {}\".format(test_loss, match, nsample, (match / nsample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet 18 with Five Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is -4.877224951171875 and accuracy is 453/1250 = 0.3624\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "cwd = os.getcwd()\n",
    "dataset_path = cwd\n",
    "dataset = ImageNetDataset(dataset_path)\n",
    "nsample=250\n",
    "\n",
    "valsampler = SubsetRandomSampler(list(range(nsample)))\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=20, sampler=valsampler)\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "device = 'cpu'\n",
    "test(resnet18, device, val_loader, nsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet 18 without Five Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is -1.0572685119628906 and accuracy is 108/250 = 0.432\n"
     ]
    }
   ],
   "source": [
    "use_crop=False\n",
    "\n",
    "dataset = ImageNetDataset(dataset_path, use_crop=use_crop)\n",
    "nsample=250\n",
    "\n",
    "valsampler = SubsetRandomSampler(list(range(nsample)))\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=20, sampler=valsampler)\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "device = 'cpu'\n",
    "test(resnet18, device, val_loader, nsample, use_crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
